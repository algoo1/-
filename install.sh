#!/bin/bash

# SigLIP-2 Server Installation Script for RunPod
# Ø³ÙƒØ±ÙŠØ¨Øª ØªØ«Ø¨ÙŠØª Ø®Ø§Ø¯Ù… SigLIP-2 Ø¹Ù„Ù‰ RunPod

set -e

echo "ðŸš€ Ø¨Ø¯Ø¡ ØªØ«Ø¨ÙŠØª SigLIP-2 Server..."

# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Python
echo "ðŸ“‹ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Python..."
if ! command -v python3 &> /dev/null; then
    echo "âŒ Python ØºÙŠØ± Ù…Ø«Ø¨Øª"
    exit 1
fi

python_version=$(python3 --version | cut -d' ' -f2)
echo "âœ… Python version: $python_version"

# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† pip
echo "ðŸ“‹ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† pip..."
if ! command -v pip3 &> /dev/null; then
    echo "âŒ pip ØºÙŠØ± Ù…Ø«Ø¨Øª"
    exit 1
fi

# ØªØ­Ø¯ÙŠØ« pip
echo "ðŸ”„ ØªØ­Ø¯ÙŠØ« pip..."
pip3 install --upgrade pip

# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† CUDA
echo "ðŸ“‹ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† CUDA..."
if command -v nvidia-smi &> /dev/null; then
    echo "âœ… NVIDIA GPU Ù…ØªØ§Ø­:"
    nvidia-smi --query-gpu=name,memory.total --format=csv,noheader
    CUDA_AVAILABLE=true
else
    echo "âš ï¸ NVIDIA GPU ØºÙŠØ± Ù…ØªØ§Ø­ - Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… CPU"
    CUDA_AVAILABLE=false
fi

# ØªØ«Ø¨ÙŠØª PyTorch
echo "ðŸ”„ ØªØ«Ø¨ÙŠØª PyTorch..."
if [ "$CUDA_AVAILABLE" = true ]; then
    pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
    echo "âœ… ØªÙ… ØªØ«Ø¨ÙŠØª PyTorch Ù…Ø¹ Ø¯Ø¹Ù… CUDA"
else
    pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
    echo "âœ… ØªÙ… ØªØ«Ø¨ÙŠØª PyTorch Ù„Ù„Ù€ CPU"
fi

# ØªØ«Ø¨ÙŠØª Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª
echo "ðŸ”„ ØªØ«Ø¨ÙŠØª Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ù…Ø´Ø±ÙˆØ¹..."
if [ -f "requirements.txt" ]; then
    pip3 install -r requirements.txt
    echo "âœ… ØªÙ… ØªØ«Ø¨ÙŠØª Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª"
else
    echo "âŒ Ù…Ù„Ù requirements.txt ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯"
    exit 1
fi

# ØªØ­Ù‚Ù‚ Ù…Ù† ØªØ«Ø¨ÙŠØª transformers
echo "ðŸ“‹ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù…ÙƒØªØ¨Ø© transformers..."
python3 -c "import transformers; print('âœ… transformers version:', transformers.__version__)"

# ØªØ­Ù‚Ù‚ Ù…Ù† ØªØ«Ø¨ÙŠØª fastapi
echo "ðŸ“‹ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù…ÙƒØªØ¨Ø© FastAPI..."
python3 -c "import fastapi; print('âœ… FastAPI version:', fastapi.__version__)"

# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ cache Ù„Ù„Ù†Ù…Ø§Ø°Ø¬
echo "ðŸ“ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ cache..."
mkdir -p /workspace/model_cache
export TRANSFORMERS_CACHE=/workspace/model_cache
echo "export TRANSFORMERS_CACHE=/workspace/model_cache" >> ~/.bashrc

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø³Ø¨Ù‚Ø§Ù‹ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
echo "ðŸ¤– Ù‡Ù„ ØªØ±ÙŠØ¯ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø³Ø¨Ù‚Ø§Ù‹ØŸ (y/n)"
read -r preload_model

if [ "$preload_model" = "y" ] || [ "$preload_model" = "Y" ]; then
    echo "â¬‡ï¸ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ SigLIP-2..."
    python3 -c "
from transformers import AutoModel, AutoProcessor
import torch

print('ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬...')
model_name = 'google/siglip2-so400m-patch14-384'
try:
    model = AutoModel.from_pretrained(model_name, cache_dir='/workspace/model_cache')
    processor = AutoProcessor.from_pretrained(model_name, cache_dir='/workspace/model_cache')
    print('âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­')
except Exception as e:
    print(f'âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}')
"
fi

# Ø¥Ù†Ø´Ø§Ø¡ Ø³ÙƒØ±ÙŠØ¨Øª Ø¨Ø¯Ø¡ Ø³Ø±ÙŠØ¹
echo "ðŸ“ Ø¥Ù†Ø´Ø§Ø¡ Ø³ÙƒØ±ÙŠÙ¾Øª Ø§Ù„Ø¨Ø¯Ø¡ Ø§Ù„Ø³Ø±ÙŠØ¹..."
cat > quick_start.py << 'EOF'
#!/usr/bin/env python3
import subprocess
import sys
import os

def main():
    print("ðŸš€ SigLIP-2 Server Quick Start")
    print("=" * 40)
    
    # ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
    if not os.path.exists('main.py'):
        print("âŒ main.py ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯")
        return
    
    # ØªØ¹ÙŠÙŠÙ† Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©
    os.environ['TRANSFORMERS_CACHE'] = '/workspace/model_cache'
    
    print("ðŸ”„ Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø®Ø§Ø¯Ù…...")
    print("ðŸ“¡ Ø§Ù„Ø®Ø§Ø¯Ù… Ù…ØªØ§Ø­ Ø¹Ù„Ù‰: http://0.0.0.0:8000")
    print("ðŸ“š Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ Ù…ØªØ§Ø­Ø© Ø¹Ù„Ù‰: http://0.0.0.0:8000/docs")
    print("ðŸ’¡ Ø§Ø¶ØºØ· Ctrl+C Ù„Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø®Ø§Ø¯Ù…")
    print("-" * 40)
    
    # ØªØ´ØºÙŠÙ„ Ø§Ù„Ø®Ø§Ø¯Ù…
    try:
        subprocess.run([
            sys.executable, 'main.py',
            '--host', '0.0.0.0',
            '--port', '8000'
        ])
    except KeyboardInterrupt:
        print("\nðŸ‘‹ ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø®Ø§Ø¯Ù…")

if __name__ == "__main__":
    main()
EOF

chmod +x quick_start.py

# Ø§Ø®ØªØ¨Ø§Ø± Ø³Ø±ÙŠØ¹
echo "ðŸ§ª Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ø®ØªØ¨Ø§Ø± Ø³Ø±ÙŠØ¹..."
python3 -c "
try:
    import torch
    import transformers
    import fastapi
    import uvicorn
    from PIL import Image
    print('âœ… Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª ØªØ¹Ù…Ù„ Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­')
    
    if torch.cuda.is_available():
        print(f'âœ… CUDA Ù…ØªØ§Ø­ - Ø§Ù„Ø¬Ù‡Ø§Ø²: {torch.cuda.get_device_name(0)}')
        print(f'âœ… Ø°Ø§ÙƒØ±Ø© GPU: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB')
    else:
        print('â„¹ï¸ CUDA ØºÙŠØ± Ù…ØªØ§Ø­ - Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… CPU')
        
except ImportError as e:
    print(f'âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª: {e}')
    exit(1)
"

echo ""
echo "ðŸŽ‰ ØªÙ… Ø§Ù„ØªØ«Ø¨ÙŠØª Ø¨Ù†Ø¬Ø§Ø­!"
echo "=" * 50
echo "Ù„Ù„Ø¨Ø¯Ø¡ Ø§Ù„Ø³Ø±ÙŠØ¹ØŒ Ø§Ø³ØªØ®Ø¯Ù…:"
echo "  python3 quick_start.py"
echo ""
echo "Ø£Ùˆ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø®Ø§Ø¯Ù… Ù…Ø¨Ø§Ø´Ø±Ø©:"
echo "  python3 main.py"
echo ""
echo "Ø£Ùˆ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø³ÙƒØ±ÙŠÙ¾Øª Ø§Ù„ØªØ´ØºÙŠÙ„:"
echo "  ./scripts/run_server.sh"
echo "=" * 50
